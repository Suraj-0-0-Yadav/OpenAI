{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "346c9e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2caa8575",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from dotenv import load_dotenv, find_dotenv\n",
    "# _ = load_dotenv(find_dotenv()) # read local .env file\n",
    "\n",
    "# openai.api_key = os.environ['OPENAI_API_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "71470edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import dotenv_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4b232243",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = dotenv_values('../.env')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "13ae86a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = config['OPENAI_API_KEY']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2003596d",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "814f09a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = openai.Completion.create(model='text-davinci-003',\n",
    "                                    prompt=\"Tha rat says \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "83f61067",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\"Squeak! Squeak!\"\n"
     ]
    }
   ],
   "source": [
    "print(response['choices'][0]['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f89e8ba9",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8207f354",
   "metadata": {},
   "source": [
    "### [max_tokens](https://platform.openai.com/docs/api-reference/completions/create#completions/create-max_tokens)\n",
    "#### Defaults to 16\n",
    "The maximum number of tokens to generate in the completion.\n",
    "\n",
    "The token count of your prompt plus max_tokens cannot exceed the model's context length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a70760f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1. Tokyo, Japan\n",
      "2. Delhi, India\n",
      "3. Shanghai, China\n",
      "4. Sao Paulo, Brazil\n",
      "5. Mexico City, Mexico\n",
      "6. Cairo, Egypt\n",
      "7. Beijing, China\n",
      "8. Dhaka, Bangladesh\n",
      "9. Mumbai, India\n",
      "10. Osaka, Japan\n"
     ]
    }
   ],
   "source": [
    "response = openai.Completion.create(model='text-davinci-003',\n",
    "                                    prompt=\"The top 10 most populated cities are:  \",\n",
    "                                    max_tokens=100)\n",
    "\n",
    "print(response['choices'][0]['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f84d48e3",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46455207",
   "metadata": {},
   "source": [
    "### [stop_sequences](https://platform.openai.com/docs/api-reference/completions/create#completions/create-stop) \n",
    "##### string or array Optional Defaults to null\n",
    "The returned text will not contain the stop sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "009d7f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = openai.Completion.create(model = 'text-davinci-003',\n",
    "                         prompt = 'Generate a list of best movies of all time',\n",
    "                         max_tokens = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cece8e76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject text_completion id=cmpl-7SRJwUGQYkXhWyiHjqXvlhss8Hstn at 0x2278e252d40> JSON: {\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"finish_reason\": \"length\",\n",
       "      \"index\": 0,\n",
       "      \"logprobs\": null,\n",
       "      \"text\": \"\\n\\n1. The Godfather (1972)\\n2. The Shawshank Redemption (1994)\\n3. Schindler's List (1993)\\n4. Casablanca (1942)\\n5. Apocalypse Now (1979)\\n6. The Godfather Part II (1974)\\n7. Citizen Kane (1941)\\n8. Raging Bull (1980)\\n9. 2001: A Space Odyssey (1968)\\n10. Gone with the Wind (1939)\\n11. Lawrence of Arabia (1962)\\n12. Singin' in the Rain (1952)\\n13. The Searchers (1956)\\n14. Sunset Boulevard (1950)\\n15. The Third Man (1949)\\n16. The Maltese Falcon (1941)\\n17. Jaws (1975)\\n18. Chinatown (1974)\\n19. The Bridge on the River Kwai (1957)\\n20. Rear Window (1954\"\n",
       "    }\n",
       "  ],\n",
       "  \"created\": 1687012560,\n",
       "  \"id\": \"cmpl-7SRJwUGQYkXhWyiHjqXvlhss8Hstn\",\n",
       "  \"model\": \"text-davinci-003\",\n",
       "  \"object\": \"text_completion\",\n",
       "  \"usage\": {\n",
       "    \"completion_tokens\": 200,\n",
       "    \"prompt_tokens\": 10,\n",
       "    \"total_tokens\": 210\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b1bf3027",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1. The Godfather (1972)\n",
      "2. The Shawshank Redemption (1994)\n",
      "3. Schindler's List (1993)\n",
      "4. Casablanca (1942)\n",
      "5. Apocalypse Now (1979)\n",
      "6. The Godfather Part II (1974)\n",
      "7. Citizen Kane (1941)\n",
      "8. Raging Bull (1980)\n",
      "9. 2001: A Space Odyssey (1968)\n",
      "10. Gone with the Wind (1939)\n",
      "11. Lawrence of Arabia (1962)\n",
      "12. Singin' in the Rain (1952)\n",
      "13. The Searchers (1956)\n",
      "14. Sunset Boulevard (1950)\n",
      "15. The Third Man (1949)\n",
      "16. The Maltese Falcon (1941)\n",
      "17. Jaws (1975)\n",
      "18. Chinatown (1974)\n",
      "19. The Bridge on the River Kwai (1957)\n",
      "20. Rear Window (1954\n"
     ]
    }
   ],
   "source": [
    "print(response['choices'][0]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "534e3b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = openai.Completion.create(model = 'text-davinci-003',\n",
    "                                    prompt = 'Generate a list of best movies of all time',\n",
    "                                    max_tokens = 200,\n",
    "                                    stop='5.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8b0f0bf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject text_completion id=cmpl-7SRO4puLM18qMMGU4uReBgYPoSR7g at 0x2278ecf2bb0> JSON: {\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"finish_reason\": \"stop\",\n",
       "      \"index\": 0,\n",
       "      \"logprobs\": null,\n",
       "      \"text\": \"\\n\\n1. The Godfather \\n2. Schindler's List \\n3. The Shawshank Redemption \\n4. The Godfather Part II \\n\"\n",
       "    }\n",
       "  ],\n",
       "  \"created\": 1687012816,\n",
       "  \"id\": \"cmpl-7SRO4puLM18qMMGU4uReBgYPoSR7g\",\n",
       "  \"model\": \"text-davinci-003\",\n",
       "  \"object\": \"text_completion\",\n",
       "  \"usage\": {\n",
       "    \"completion_tokens\": 36,\n",
       "    \"prompt_tokens\": 10,\n",
       "    \"total_tokens\": 46\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "015198c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1. The Godfather \n",
      "2. Schindler's List \n",
      "3. The Shawshank Redemption \n",
      "4. The Godfather Part II \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(response['choices'][0]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0082f763",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "You are a chatbot that speaks like a toddler.\n",
    "\n",
    "User: Hi, how are you?\n",
    "Chatbot: I'm good\n",
    "User: Tell me about your family\n",
    "Chatbot: I have a mommy and a daddy and a baby sister and two kitties\n",
    "User: What do you do for fun?\n",
    "Chatbot: I like to play with my toys, color, go outside and explore, play with my kitties, read stories, and play games with my family.\n",
    "User: \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5e6d65ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = openai.Completion.create(model = 'text-davinci-003',\n",
    "                                    prompt = prompt,\n",
    "                                    max_tokens = 200,\n",
    "                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "99b6a69b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject text_completion id=cmpl-7SRbQEO8xfJMNZjmuJQGpBxi0kgbC at 0x2278ece35b0> JSON: {\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"finish_reason\": \"stop\",\n",
       "      \"index\": 0,\n",
       "      \"logprobs\": null,\n",
       "      \"text\": \"That sounds like a lot of fun. What's your favorite toy?\\n\\nChatbot: My favorite toy is my toy dinosaur!\"\n",
       "    }\n",
       "  ],\n",
       "  \"created\": 1687013644,\n",
       "  \"id\": \"cmpl-7SRbQEO8xfJMNZjmuJQGpBxi0kgbC\",\n",
       "  \"model\": \"text-davinci-003\",\n",
       "  \"object\": \"text_completion\",\n",
       "  \"usage\": {\n",
       "    \"completion_tokens\": 27,\n",
       "    \"prompt_tokens\": 109,\n",
       "    \"total_tokens\": 136\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f103506",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "20623545",
   "metadata": {},
   "source": [
    "**But I want one response at a time like User or Chatbot Not both same time like above**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2ac4f01f",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = openai.Completion.create(model = 'text-davinci-003',\n",
    "                                    prompt = prompt,\n",
    "                                    max_tokens = 200,\n",
    "                                    stop=['User:','Chatbot:'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c8ee2ec7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject text_completion id=cmpl-7SReQXRcefkZSQa5p1zGxQeuexf78 at 0x2278ecf06d0> JSON: {\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"finish_reason\": \"stop\",\n",
       "      \"index\": 0,\n",
       "      \"logprobs\": null,\n",
       "      \"text\": \"That sounds like fun! What is your favorite game?\\n\\n\"\n",
       "    }\n",
       "  ],\n",
       "  \"created\": 1687013830,\n",
       "  \"id\": \"cmpl-7SReQXRcefkZSQa5p1zGxQeuexf78\",\n",
       "  \"model\": \"text-davinci-003\",\n",
       "  \"object\": \"text_completion\",\n",
       "  \"usage\": {\n",
       "    \"completion_tokens\": 13,\n",
       "    \"prompt_tokens\": 109,\n",
       "    \"total_tokens\": 122\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "400d4613",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec62f0ad",
   "metadata": {},
   "source": [
    "## [n](https://platform.openai.com/docs/api-reference/completions/create#completions/create-n)\n",
    "### n  -  integer , Optional  , Defaults to 1\n",
    "How many completions to generate for each prompt.\n",
    "\n",
    "Note: Because this parameter generates many completions, it can quickly consume your token quota. Use carefully and ensure that you have reasonable settings for max_tokens and stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "11fc7ffc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject text_completion id=cmpl-7SRlDqO3U1QLj451mUcOhQxLVQfqh at 0x2278ed17600> JSON: {\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"finish_reason\": \"stop\",\n",
       "      \"index\": 0,\n",
       "      \"logprobs\": null,\n",
       "      \"text\": \"\\n\\nQ: What did one cup of tea say to the other cup of tea?\\n\\nA: Cheers!\"\n",
       "    }\n",
       "  ],\n",
       "  \"created\": 1687014251,\n",
       "  \"id\": \"cmpl-7SRlDqO3U1QLj451mUcOhQxLVQfqh\",\n",
       "  \"model\": \"text-davinci-003\",\n",
       "  \"object\": \"text_completion\",\n",
       "  \"usage\": {\n",
       "    \"completion_tokens\": 25,\n",
       "    \"prompt_tokens\": 5,\n",
       "    \"total_tokens\": 30\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = openai.Completion.create(model = 'text-davinci-003',\n",
    "                                    prompt = 'tell me joke about Tea',\n",
    "                                    max_tokens = 200,\n",
    "                                    )\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2529ecfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject text_completion id=cmpl-7SRlYUZJtJe24Rah60bNzUCw9IID6 at 0x2278ed778d0> JSON: {\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"finish_reason\": \"stop\",\n",
       "      \"index\": 0,\n",
       "      \"logprobs\": null,\n",
       "      \"text\": \"\\n\\nQ: What did the tea bag say to the hot water? \\nA: \\\"It's been so long, I'm so steeped!\\\"\"\n",
       "    },\n",
       "    {\n",
       "      \"finish_reason\": \"stop\",\n",
       "      \"index\": 1,\n",
       "      \"logprobs\": null,\n",
       "      \"text\": \"\\n\\nQ: Why did the teapot whistle?\\nA: It was too hot to keep quiet!\"\n",
       "    }\n",
       "  ],\n",
       "  \"created\": 1687014272,\n",
       "  \"id\": \"cmpl-7SRlYUZJtJe24Rah60bNzUCw9IID6\",\n",
       "  \"model\": \"text-davinci-003\",\n",
       "  \"object\": \"text_completion\",\n",
       "  \"usage\": {\n",
       "    \"completion_tokens\": 55,\n",
       "    \"prompt_tokens\": 5,\n",
       "    \"total_tokens\": 60\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = openai.Completion.create(model = 'text-davinci-003',\n",
    "                                    prompt = 'tell me joke about Tea',\n",
    "                                    max_tokens = 200,\n",
    "                                    n=2\n",
    "                                    )\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "067959bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Q: What did the tea bag say to the hot water? \n",
      "A: \"It's been so long, I'm so steeped!\"\n",
      "\n",
      "\n",
      "Q: Why did the teapot whistle?\n",
      "A: It was too hot to keep quiet!\n"
     ]
    }
   ],
   "source": [
    "for i in range(2):\n",
    "    print(response['choices'][i]['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e57054e",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a031bdc6",
   "metadata": {},
   "source": [
    "## [echo](https://platform.openai.com/docs/api-reference/completions/create#completions/create-echo)\n",
    "### echo - boolean,  Optional,  Defaults to false\n",
    "Echo back the prompt in addition to the completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9ae27969",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "A. Jawaharlal Nehru was the first Prime Minister of India. He served from 1947-1964.\n"
     ]
    }
   ],
   "source": [
    "response = openai.Completion.create(model = 'text-davinci-003',\n",
    "                                    prompt = 'Q. Who is the first Prime Minister of India ?',\n",
    "                                    max_tokens = 200,\n",
    "                                    )\n",
    "print(response['choices'][0]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d554862a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q. Who is the first Prime Minister of India ?\n",
      "\n",
      "A. Jawaharlal Nehru was the first Prime Minister of India.\n"
     ]
    }
   ],
   "source": [
    "response = openai.Completion.create(model = 'text-davinci-003',\n",
    "                                    prompt = 'Q. Who is the first Prime Minister of India ?',\n",
    "                                    max_tokens = 200,\n",
    "                                    echo=True\n",
    "                                    )\n",
    "print(response['choices'][0]['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7848cdd",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ca3fbb",
   "metadata": {},
   "source": [
    "Comparing diff models\n",
    "```\n",
    "text-ada-001\n",
    "text-babbage-001\n",
    "text-davinci-003\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d3bfc11a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "What would you like to do?\n"
     ]
    }
   ],
   "source": [
    "response = openai.Completion.create(model = 'text-ada-001',\n",
    "                                    prompt = \"I'm sad. Make me happy please. \",\n",
    "                                    max_tokens = 200,\n",
    "                                    )\n",
    "print(response['choices'][0]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "78108f2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "This isn't really a question, but can you make me happy?\n"
     ]
    }
   ],
   "source": [
    "response = openai.Completion.create(model = 'text-babbage-001',\n",
    "                                    prompt = \"I'm sad. Make me happy please. \",\n",
    "                                    max_tokens = 200,\n",
    "                                    )\n",
    "print(response['choices'][0]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "64495f7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "It's okay to be sad sometimes! Just remember that happiness can come from both big and small moments. Find something that brings a small smile to your face like your favorite snack, playing with a pet, or a thoughtful act of kindness to another. You can also try some positive self-talk, like speaking kindly and encouragingly to yourself. We hope you find something that makes you happy!\n"
     ]
    }
   ],
   "source": [
    "response = openai.Completion.create(model = 'text-davinci-003',\n",
    "                                    prompt = \"I'm sad. Make me happy please. \",\n",
    "                                    max_tokens = 200,\n",
    "                                    )\n",
    "print(response['choices'][0]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e4472f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
